{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据归一化\n",
    "- 在sklearn当中，我们使用preprocessing.MinMaxScaler来实现这个功能。MinMaxScaler有一个重要参数，\n",
    "feature_range，控制我们希望把数据压缩到的范围，默认是[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  5.  ],\n",
       "       [ 6.25,  6.25],\n",
       "       [ 7.5 ,  7.5 ],\n",
       "       [10.  , 10.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    " \n",
    "#不太熟悉numpy的小伙伴，能够判断data的结构吗？\n",
    "#如果换成表是什么样子？\n",
    "import pandas as pd\n",
    "pd.DataFrame(data)\n",
    " \n",
    "#实现归一化\n",
    "scaler = MinMaxScaler()                             #实例化\n",
    "scaler = scaler.fit(data)                           #fit，在这里本质是生成min(x)和max(x)\n",
    "result = scaler.transform(data)                     #通过接口导出结果\n",
    "result\n",
    "\n",
    "result_ = scaler.fit_transform(data)                #训练和导出结果一步达成\n",
    " \n",
    "scaler.inverse_transform(result)                    #将归一化后的结果逆转\n",
    " \n",
    "#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中\n",
    " \n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler(feature_range=[5,10])         #依然实例化\n",
    "result = scaler.fit_transform(data)                 #fit_transform一步导出结果\n",
    "result\n",
    " \n",
    "#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了\n",
    "#此时使用partial_fit作为训练接口\n",
    "#scaler = scaler.partial_fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  使用numpy来实现归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])\n",
    " \n",
    "#归一化\n",
    "X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_nor\n",
    " \n",
    "#逆转归一化\n",
    "X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)\n",
    "X_returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据标准化\n",
    "- 当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分\n",
    "布），而这个过程，就叫做数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    " \n",
    "scaler = StandardScaler()                           #实例化\n",
    "scaler.fit(data)                                    #fit，本质是生成均值和方差\n",
    " \n",
    "scaler.mean_                                        #查看均值的属性mean_\n",
    "scaler.var_                                         #查看方差的属性var_\n",
    " \n",
    "x_std = scaler.transform(data)                      #通过接口导出结果\n",
    " \n",
    "x_std.mean()                                        #导出的结果是一个数组，用mean()查看均值\n",
    "x_std.std()                                         #用std()查看方差\n",
    " \n",
    "scaler.fit_transform(data)                          #使用fit_transform(data)一步达成结果\n",
    " \n",
    "scaler.inverse_transform(x_std)                     #使用inverse_transform逆转标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据无量纲化：StandardScaler和MinMaxScaler选哪个？\n",
    "- MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择\n",
    "- MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Narrativedata.csv\"\n",
    "                   ,index_col=0\n",
    "                  )#index_col=0将第0列作为索引，不写则认为第0列为特征\n",
    " \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- impute.SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       714 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       891 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       891 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  891 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "#填补年龄\n",
    " \n",
    "Age = data.loc[:,\"Age\"].values.reshape(-1,1)            #sklearn当中特征矩阵必须是二维\n",
    "Age[:20]\n",
    " \n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer()                              #实例化，默认均值填补\n",
    "imp_median = SimpleImputer(strategy=\"median\")           #用中位数填补\n",
    "imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补\n",
    " \n",
    "imp_mean = imp_mean.fit_transform(Age)                  #fit_transform一步完成调取结果\n",
    "imp_median = imp_median.fit_transform(Age)\n",
    "imp_0 = imp_0.fit_transform(Age)\n",
    " \n",
    "imp_mean[:20]\n",
    "imp_median[:20]\n",
    "imp_0[:20]\n",
    " \n",
    "#在这里我们使用中位数填补Age\n",
    "data.loc[:,\"Age\"] = imp_median\n",
    " \n",
    "data.info()\n",
    " \n",
    "#使用众数填补Embarked\n",
    "Embarked = data.loc[:,\"Embarked\"].values.reshape(-1,1)\n",
    "imp_mode = SimpleImputer(strategy = \"most_frequent\")\n",
    "data.loc[:,\"Embarked\"] = imp_mode.fit_transform(Embarked)\n",
    " \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用Pandas和Numpy进行填补其实更加简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'Yes', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Unknown', 'Yes', 'Yes', 'Yes', 'No', 'Unknown', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Unknown', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'Yes', 'Unknown', 'No', 'Unknown',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'Unknown', 'Unknown', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Unknown', 'No', 'Unknown', 'Unknown', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'Unknown',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'Unknown', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Unknown', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'Unknown', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'No', 'No', 'Unknown', 'Yes', 'Yes',\n",
       "       'Unknown', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'Unknown', 'Unknown', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'No',\n",
       "       'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'Unknown', 'Yes', 'Yes', 'No', 'Unknown', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'Yes', 'Yes', 'Yes', 'No', 'Unknown',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'Unknown', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Unknown', 'No', 'No', 'No', 'Unknown', 'No', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Unknown', 'Yes', 'No', 'No',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'Yes', 'Unknown', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n",
       "       'Unknown', 'Unknown', 'No', 'Yes', 'Yes', 'No', 'No', 'Unknown',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Unknown',\n",
       "       'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'Unknown', 'No', 'No',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes',\n",
       "       'Unknown', 'Yes', 'Yes', 'Unknown', 'Yes', 'Yes', 'No', 'Yes',\n",
       "       'Yes', 'Unknown', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'Unknown', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Unknown', 'Yes',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Unknown', 'No', 'Unknown', 'No',\n",
       "       'Unknown', 'Unknown', 'Yes', 'Yes', 'Unknown', 'Yes', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes',\n",
       "       'No', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'Yes', 'Yes', 'Unknown', 'No', 'No', 'Yes', 'No', 'No',\n",
       "       'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Unknown', 'Yes', 'Unknown', 'No', 'Unknown', 'No', 'Yes',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'Yes', 'Unknown', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'No',\n",
       "       'No', 'No', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Yes', 'No',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Unknown', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No', 'Unknown', 'No', 'Unknown', 'Unknown',\n",
       "       'Yes', 'Unknown', 'No', 'No', 'Yes', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Yes', 'Yes', 'Unknown', 'Unknown', 'Yes', 'No', 'Unknown', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'Unknown',\n",
       "       'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'No', 'No', 'Yes',\n",
       "       'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No', 'No', 'Unknown', 'No',\n",
       "       'No', 'Unknown', 'Unknown', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes',\n",
       "       'No', 'No', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'No', 'No', 'No',\n",
       "       'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'No', 'No', 'No', 'No', 'Yes', 'No', 'Unknown', 'No',\n",
       "       'Unknown', 'No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'No',\n",
       "       'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No',\n",
       "       'No', 'Unknown', 'No', 'No', 'No', 'Unknown', 'Unknown', 'No',\n",
       "       'Unknown', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No',\n",
       "       'No', 'Yes', 'No', 'Unknown', 'Unknown', 'Unknown', 'No', 'No',\n",
       "       'Yes', 'No', 'Unknown', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No',\n",
       "       'Yes', 'Yes', 'No', 'No', 'Unknown', 'No', 'No', 'No', 'Yes', 'No',\n",
       "       'Unknown', 'No'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_ = pd.read_csv(\"./Narrativedata.csv\"\n",
    "                   ,index_col=0\n",
    "                  )#index_col=0将第0列作为索引，不写则认为第0列为特征\n",
    "\n",
    "data_.head()\n",
    " \n",
    "data_.loc[:,\"Age\"] = data_.loc[:,\"Age\"].fillna(data_.loc[:,\"Age\"].median())\n",
    "#.fillna 在DataFrame里面直接进行填补\n",
    " \n",
    "data_.dropna(axis=0,inplace=True)\n",
    "#.dropna(axis=0)删除所有有缺失值的行，.dropna(axis=1)删除所有有缺失值的列\n",
    "#参数inplace，为True表示在原数据集上进行修改，为False表示生成一个复制对象，不修改原数据，默认False\n",
    "# _data_ = data_.drop(axis=0,inplace=False)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "y = data_.iloc[:,-1]                         #要输入的是标签，不是特征矩阵，所以允许一维\n",
    " \n",
    "le = LabelEncoder()                         #实例化\n",
    "le = le.fit(y)                              #导入数据\n",
    "label = le.transform(y)                     #transform接口调取结果\n",
    " \n",
    "le.classes_                                 #属性.classes_查看标签中究竟有多少类别\n",
    "label                                       #查看获取的结果label\n",
    " \n",
    "le.fit_transform(y)                         #也可以直接fit_transform一步到位\n",
    " \n",
    "le.inverse_transform(label)                 #使用inverse_transform可以逆转"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理分类型特征：编码与哑变量\n",
    "- preprocessing.LabelEncoder：标签专用，能够将分类转换为分类数值\n",
    "- 比如几个特征值之间没有数值关系，如果转换为数字它们之间却有了数值关系（我不确定，好像数值间隔一样就代表没有关系吧）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "y = data.iloc[:,-1]                         #要输入的是标签，不是特征矩阵，所以允许一维\n",
    " \n",
    "le = LabelEncoder()                         #实例化\n",
    "le = le.fit(y)                              #导入数据\n",
    "label = le.transform(y)                     #transform接口调取结果\n",
    " \n",
    "le.classes_                                 #属性.classes_查看标签中究竟有多少类别\n",
    "label                                       #查看获取的结果label\n",
    " \n",
    "le.fit_transform(y)                         #也可以直接fit_transform一步到位\n",
    " \n",
    "le.inverse_transform(label)                 #使用inverse_transform可以逆转\n",
    "\n",
    "data.iloc[:,-1] = label                     #让标签等于我们运行出来的结果\n",
    " \n",
    "data.head()\n",
    " \n",
    "#如果不需要教学展示的话我会这么写：\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 也就是说loc是根据index来索引，比如下边的df定义了一个index，那么loc就根据这个index来索引对应的行。iloc并不是根据index来索引，而是根据行号来索引，行号从0开始，逐次加1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Embarked  Survived\n",
       "0  22.0  1.0       2.0         0\n",
       "1  38.0  0.0       0.0         2\n",
       "2  26.0  0.0       2.0         2\n",
       "3  35.0  0.0       2.0         2\n",
       "4  35.0  1.0       2.0         0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    " \n",
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "data_ = data.copy()\n",
    " \n",
    "data_.head()\n",
    " \n",
    "OrdinalEncoder().fit(data_.iloc[:,1:-1]).categories_\n",
    " \n",
    "data_.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data_.iloc[:,1:-1])\n",
    " \n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://gitee.com/liangxinixn/blog002/raw/master/image01/20210112210045.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值变量理解理解\n",
    "- 舱门（S，C，Q）之间没有数学关系，是相互独立的，如果变为0，1，2是否有问题\n",
    "- 不可能S+1=C\n",
    "- 那么怎么解决这些问题\n",
    "- 学历，体重\n",
    "- 0和1两个估计可以，有你没我的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 不能使用0，1，2转换，要使用哑变量\n",
    "![](https://gitee.com/liangxinixn/blog002/raw/master/image01/20210112210509.png)\n",
    "- 这样来处理模型才能够理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Embarked  Survived\n",
       "0  22.0  1.0       2.0         0\n",
       "1  38.0  0.0       0.0         2\n",
       "2  26.0  0.0       2.0         2\n",
       "3  35.0  0.0       2.0         2\n",
       "4  35.0  1.0       2.0         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    " \n",
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "data_ = data.copy()\n",
    " \n",
    "data_.head()\n",
    " \n",
    "OrdinalEncoder().fit(data_.iloc[:,1:-1]).categories_\n",
    " \n",
    "data_.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data_.iloc[:,1:-1])\n",
    " \n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived  Female  Male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0  22.0         0     0.0   1.0         0.0         0.0         1.0\n",
       "1  38.0         2     1.0   0.0         1.0         0.0         0.0\n",
       "2  26.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "3  35.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "4  35.0         0     0.0   1.0         0.0         0.0         1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    " \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = data.iloc[:,1:-1]\n",
    " \n",
    "enc = OneHotEncoder(categories='auto').fit(X)\n",
    "result = enc.transform(X).toarray()\n",
    "result\n",
    " \n",
    "#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步\n",
    "OneHotEncoder(categories='auto').fit_transform(X).toarray()\n",
    " \n",
    "#依然可以还原\n",
    "pd.DataFrame(enc.inverse_transform(result))\n",
    " \n",
    "enc.get_feature_names()#返回每一个经过哑变量后生成稀疏矩阵列的名字\n",
    " \n",
    "result\n",
    "result.shape\n",
    " \n",
    "#axis=1,表示跨行进行合并，也就是将两表左右相连，如果是axis=0，就是将量表上下相连\n",
    "newdata = pd.concat([data,pd.DataFrame(result)],axis=1)\n",
    " \n",
    "newdata.head()\n",
    " \n",
    "newdata.drop([\"Sex\",\"Embarked\"],axis=1,inplace=True)\n",
    " \n",
    "newdata.columns = [\"Age\",\"Survived\",\"Female\",\"Male\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\"]\n",
    " \n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理连续型特征：二值化与分段\n",
    "- 根据阈值将数据二值化（将特征值设置为0或1），用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈值的值映射为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex Embarked  Survived\n",
       "0  0.0    male        S         0\n",
       "1  1.0  female        C         2\n",
       "2  0.0  female        S         2\n",
       "3  1.0  female        S         2\n",
       "4  1.0    male        S         0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将年龄二值化\n",
    " \n",
    "data_2 = data.copy()\n",
    " \n",
    "from sklearn.preprocessing import Binarizer\n",
    "X = data_2.iloc[:,0].values.reshape(-1,1)               #类为特征专用，所以不能使用一维数组\n",
    "transformer = Binarizer(threshold=30).fit_transform(X)\n",
    " \n",
    "data_2.iloc[:,0] = transformer\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preprocessing.KBinsDiscretizer这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    " \n",
    "X = data.iloc[:,0].values.reshape(-1,1) \n",
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit_transform(X)\n",
    " \n",
    "#查看转换后分的箱：变成了一列中的三箱\n",
    "set(est.fit_transform(X).ravel())\n",
    " \n",
    "est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "#查看转换后分的箱：变成了哑变量\n",
    "est.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n",
    "- 特征提取：从文字，图像，声音等其他非结构化数据中提取新信息作为特征。\n",
    "- 特征创造：把现有特征进行组合，或互相计算，得到新的特征\n",
    "- 特征选择：从所有的特征中，选择出有意义，对模型有帮助的特征，以避免必须将所有特征都导入模型去训练的情况。\n",
    "---\n",
    "- 特征工程的第一步是：理解业务。也就是每条数据的意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。\\n用这个数据举例，能更够体现特征工程的重要性。\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入数据，让我们使用digit recognizor数据来一展身手\n",
    " \n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./digit recognizor.csv\")\n",
    " \n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    "\n",
    "X.shape\n",
    " \n",
    "\"\"\"\n",
    "这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。\n",
    "用这个数据举例，能更够体现特征工程的重要性。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://gitee.com/liangxinixn/blog002/raw/master/image01/20210112220011.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>698</th>\n",
       "      <th>699</th>\n",
       "      <th>700</th>\n",
       "      <th>701</th>\n",
       "      <th>702</th>\n",
       "      <th>703</th>\n",
       "      <th>704</th>\n",
       "      <th>705</th>\n",
       "      <th>706</th>\n",
       "      <th>707</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  698  699  700  701  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   702  703  704  705  706  707  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 708 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold()                      #实例化，不填参数默认方差为0\n",
    "X_var0 = selector.fit_transform(X)                  #获取删除不合格特征之后的新特征矩阵\n",
    " \n",
    "#也可以直接写成 X = VairanceThreshold().fit_transform(X)\n",
    " \n",
    "X_var0.shape#(42000, 708)\n",
    "pd.DataFrame(X_var0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# X.var()#每一列的方差\n",
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)\n",
    " \n",
    "X.var().values\n",
    " \n",
    "np.median(X.var().values)\n",
    " \n",
    "X_fsvar.shape#(42000, 392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#若特征是伯努利随机变量，假设p=0.8，即二分类特征中某种分类占到80%以上的时候删除特征\n",
    "X_bvar = VarianceThreshold(.8 * (1 - .8)).fit_transform(X)\n",
    "X_bvar.shape#(42000,685)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN vs 随机森林在不同方差过滤效果下的对比\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    " \n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    " \n",
    "X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING：35mins +】======#\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()\n",
    " \n",
    "#python中的魔法命令，可以直接使用%%timeit来计算运行这个cell中的代码所需的时间\n",
    "#为了计算所需的时间，需要将这个cell中的代码运行很多次（通常是7次）后求平均值，因此运行%%timeit的时间会\n",
    "# 远远超过cell中的代码单独运行的时间\n",
    " \n",
    "#======【TIME WARNING：4 hours】======#\n",
    "%%timeit\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======【TIME WARNING：20 mins+】======#\n",
    "cross_val_score(KNN(),X_fsvar,y,cv=5).mean()\n",
    " \n",
    "#======【TIME WARNING：2 hours】======#\n",
    "%%timeit\n",
    "cross_val_score(KNN(),X,y,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(RFC(n_estimators=10,random_state=0),X,y,cv=5).mean()\n",
    "#0.9380003861799541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(RFC(n_estimators=10,random_state=0),X_fsvar,y,cv=5).mean()\n",
    "#0.9388098166696807"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 后面的运行时间太长，看pdf把"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
